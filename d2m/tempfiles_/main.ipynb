{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiopaths,midipaths=data.pathscan()\n",
    "print(f'There are {len(audiopaths)} audiofiles,\\nThere are {len(midipaths)} midifiles.')\n",
    "\n",
    "csv=data.get_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths\n",
    "midisample,audiosample=paths.sample_files()\n",
    "print(midisample,\"\\n\",audiosample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "#define analysis parameters\n",
    "def analysis_parameters():\n",
    "    sampling_rate=16000  #for instance: if mode 16, sr = 16kHz\n",
    "    window_size = sampling_rate\n",
    "    overlap = int(window_size*0.75)\n",
    "    hop_length = (window_size-overlap)\n",
    "    return sampling_rate, window_size, hop_length\n",
    "\n",
    "def _windows(data, window_size, hop_length):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += hop_length\n",
    "                    \n",
    "#sampling_rate=16000\n",
    "raw, sr =librosa.load(audiosample, sr=sampling_rate, mono=True)\n",
    "print(raw.shape)\n",
    "\n",
    "frames = []\n",
    "#get windows out of the raw waveform\n",
    "for count_frames,(start,end) in enumerate(_windows(raw,window_size,hop_length)):\n",
    "if(len(raw[start:end]) == window_size):\n",
    "    print(start,end)\n",
    "    frame = raw[start:end]#rectangular window\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(audio_path, folds, files, mode):\n",
    "    \n",
    "  def _windows(data, window_size, hop_length):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "      yield start, start + window_size\n",
    "      start += hop_length\n",
    "\n",
    "  def normalize(data):#in the space [-1,1]\n",
    "    #return (data - np.min(data)) / (np.max(data) - np.min(data))#[0,1]\n",
    "    return (2*(data-np.min(data))/(np.max(data) - np.min(data)))-1\n",
    "  \n",
    "\n",
    "  features = []\n",
    " \n",
    "  extr = True\n",
    "  if extr == True:\n",
    "    \n",
    "    print('Preprocessing data ........ ')\n",
    "    \n",
    "    sampling_rate, window_size, hop_length = analysis_parameters(mode)\n",
    "    print(f'sampling_rate: {sampling_rate}, window_size: {window_size}, hop_length: {hop_length}')\n",
    "\n",
    "    shape_print=True\n",
    "\n",
    "\n",
    "    for count_files, file in tqdm(enumerate(audiofiles)):\n",
    "      name = file.split('.wav')[0]\n",
    "\n",
    "      #readfile\n",
    "      raw, sr =librosa.load(audio_path+file, sr=sampling_rate, mono=True)\n",
    "      #print(f'{file} had length {len(raw)}')\n",
    "\n",
    "      #normalize\n",
    "      raw = normalize(raw)\n",
    "      \n",
    "      frames = []\n",
    "      #get windows out of the raw waveform\n",
    "      for count_frames,(start,end) in enumerate(_windows(raw,window_size,hop_length)):\n",
    "        if(len(raw[start:end]) == window_size):\n",
    "          #print(start,end)\n",
    "          frame = raw[start:end]#rectangular window\n",
    "\n",
    "          #flatten\n",
    "          #implemented inside the model\n",
    "\n",
    "          frames.append(frame)\n",
    "      \n",
    "      features.append(frames)\n",
    "     \n",
    "\n",
    "      if shape_print:\n",
    "            print('\\nFeature Shape Check\\n')\n",
    "            print(f'raw has len:{len(raw)/sampling_rate}')\n",
    "            print(f'Postprocessed feature has shape : {np.asarray(features).shape} with min:{np.asarray(features[0]).min()} and max:{np.asarray(features[0]).max()}]')\n",
    "            print()\n",
    "            shape_print = False\n",
    "\n",
    "  #'''\n",
    "  print('len(features)-features',len(features))\n",
    "  print('len(features[0])-freq_domain',len(features[0]))\n",
    "  print('labels',len(labels))\n",
    "  #'''\n",
    "  return features\n",
    "\n",
    "#get analysis parameters\n",
    "sampling_rate, window_size, hop_length = analysis_parameters(mode)\n",
    "print(f'sampling_rate: {sampling_rate}, window_size: {window_size}, hop_length: {hop_length}')\n",
    "\n",
    "#extract_features       \n",
    "features = preprocess_data(audio_path, folds, audiofiles, mode)\n",
    "#features, labels, folders = extract_mel_spectogram(audio_path,us8k,folds,audiofiles,sampling_rate,hop_length,fft_points,mel_bands)\n",
    "print(f' feature\\'s len : {len(features)}, labels : {len(labels)}, folders : {len(folders)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Audio-data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csv.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#styles dist\n",
    "styles=csv['style'].values\n",
    "unq_styles=csv['style'].unique()\n",
    "#print(unq_styles)\n",
    "#print(type(styles))\n",
    "#print(len(styles))\n",
    "\n",
    "#beats per seconds dist\n",
    "bpms=csv['bpm'].values\n",
    "#print(type(bpms))\n",
    "#print(len(bpms))\n",
    "\n",
    "beatfill=csv['beat_type'].values\n",
    "#print(beatfill)\n",
    "unq_beatfill=csv['beat_type'].unique()\n",
    "#print(unq_beatfill)\n",
    "\n",
    "#Durations\n",
    "durations=csv['duration'].values\n",
    "unq_durations=csv['duration'].unique()\n",
    "print(len(durations))\n",
    "print(len(unq_durations))\n",
    "\n",
    "splits=csv['split'].values\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio-technical specification analysis\n",
    "#44100\n",
    "#24bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_bpm_mean_dist=csv.groupby(['split'])['bpm'].mean()\n",
    "split_bpm_std_dist=csv.groupby(['split'])['bpm'].std()\n",
    "print(f'split_bpm_mean_dist : {split_bpm_mean_dist}\\n')\n",
    "print(f'split_bpm_std_dist : {split_bpm_std_dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERASEEEEEEE\n",
    "fig ,ax = plt.subplots(figsize=(7,7))\n",
    "ax.set_title('split_bpm_mean_dist', y=1.08)\n",
    "ax.pie(split_bpm_mean_dist, labels=split_bpm_mean_dist.index, autopct='%1.1f%%', shadow=False, startangle=90 ,radius=37,data=split_bpm_mean_dist)\n",
    "ax.axis('equal')#circle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERASEEEEEEE\n",
    "# Plot Class_dist\n",
    "fig ,ax = plt.subplots(figsize=(7,7))\n",
    "ax.set_title('split_bpm_std_dist', y=1.08)\n",
    "ax.pie(split_bpm_std_dist, labels=split_bpm_std_dist.index, autopct='%1.1f%%', shadow=False, startangle=90 ,radius=37)\n",
    "ax.axis('equal')#circle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.groupby(['bpm'])['split'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "fig ,ax = plt.subplots(figsize=(12,12))\n",
    "ax.set_title('Split Distribution', y=1.08)\n",
    "ax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%', shadow=False, startangle=90 ,radius=37)\n",
    "ax.axis('equal')#circle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Midi-data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(midipaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csv[csv['midi_filename']==\"220_rock-halftime_140_fill_4-4_6.midi\"])\n",
    "print(csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido as md\n",
    "\n",
    "\n",
    "mid = md.MidiFile(\"/data/pl/samples/220_rock-halftime_140_fill_4-4_6.midi\", clip=True)#midipaths[0]\n",
    "print(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in mid.tracks:\n",
    "    print(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in mid.tracks[0]:\n",
    "    print(msg)\n",
    "    print(type(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in mid.tracks[1]:\n",
    "    #print(msg)\n",
    "    msg=str(msg)\n",
    "    print(msg.split(' ')[0])\n",
    "    #parse string message to store annotations {1.note = the drum comp class, 2.velocity , 3.time)\n",
    "    \n",
    "    #print(type(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = md.MidiFile('sample.midi', clip=True)\n",
    "\n",
    "message_numbers = []\n",
    "duplicates = []\n",
    "\n",
    "for track in cv1.tracks:\n",
    "    print(track)\n",
    "    print(len(track))\n",
    "    if len(track) in message_numbers:\n",
    "        duplicates.append(track)\n",
    "    else:\n",
    "        message_numbers.append(len(track))\n",
    "\n",
    "for track in duplicates:\n",
    "    print(track)\n",
    "    cv1.tracks.remove(track)\n",
    "\n",
    "#cv1.save('new_song.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
